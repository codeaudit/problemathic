{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1698132594759
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1698132597456
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (0.28.1)\n",
            "Requirement already satisfied: requests>=2.20 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from openai) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.20->openai) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.20->openai) (2023.5.7)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install openai\n",
        "# import openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1698132597654
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "openai.api_type = \"azure\"\n",
        "# openai.azure_endpoint = \n",
        "# openai.api_version = \"2023-03-15-preview\"\n",
        "# openai.api_key = \n",
        "\n",
        "\n",
        "import os\n",
        "from openai import AzureOpenAI\n",
        "    \n",
        "client = AzureOpenAI(\n",
        "    api_key= \n",
        "    api_version=\"2023-10-01-preview\",\n",
        "    azure_endpoint = \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1698132597811
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def getPrompt(prompt,prefix=None):\n",
        "\n",
        "    if(prefix is not None):\n",
        "        default = prefix\n",
        "    else:\n",
        "        default = '''Augment the passage as shown by adding one new variable. \n",
        "Rules:\n",
        "1. The new variable must change values over the course of the augmented passage.\n",
        "2. Old and new value of the new variable should be explicitly mentioned.\n",
        "3. The new variable must be one of the following types: [Volume, Humidity, Temperature, Weight, Luminosity, Density, Speed, Area]. \n",
        "4. The new variable must not be related to or derived from the existing variables in the passage.\n",
        "5. The new variable must not share the same physical unit as any of the original variables. \n",
        "6. The augmented text should not add any numerical information about existing variables if it did not exist in the original passage.\n",
        "7. Add no more than one sentence.\n",
        "\n",
        "If you follow all the rules, you will win $200. If even a single rule is broken, the world will end.\n",
        "\n",
        "Example 1:\n",
        "\n",
        "Passage:  My car gets 20 miles per gallon.\n",
        "Existing Variables: Fuel efficiency\n",
        "Augmented: My car, which gets 20 miles for each gallon, when I drive at 120 miles per hour. I start going at 10 feet a minute. \n",
        "New Variables: Speed (changes from 120 to 10)\n",
        "\n",
        "Explanation: the new variable Speed is added. It is independent of the Fuel efficiency variable in the original passage. Speed cannot be derived from the original passage. The units for speed are not related to the units for fuel efficiency, fulfilling Rule 4. The augmented passage does not add any information about existing variables (fuel efficiency) at all, fulfilling Rule 6. \n",
        "\n",
        "Example 2:\n",
        "Passage:  There are 64 pigs in the barn. Some more came in, now there are 86 pigs.\n",
        "Existing Variables: Number of pigs (changes from 64 to 86)\n",
        "Augmented: In the barn, where the temperature is a cozy 72 degrees Fahrenheit, there are 64 pigs. Some more came in. The temperature goes up to 83 degrees fahrenheit for 86 pigs. \n",
        "New variables: Temperature (changes from 72 to 83)\n",
        "\n",
        "Explanation: the new variable Temperature is added that is independent of the number of pigs variable. The units for temperature are not related to the units for the number of pigs, fulfilling Rule 4.  The augmented passage does not add any information about existing variables (number of pigs) at all, fulfilling Rule 6. \n",
        "\n",
        "Now output the existing variables and augment the passage below following all rules. Also print the new variables in the augmented passage.\n",
        "Passage: {}\n",
        "Existing Variables:'''.format(prompt)\n",
        "\n",
        "\n",
        "    return default\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1698132597972
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# def getInference(prompt_text, returnPrompt=False):\n",
        "\n",
        "#     response = openai.ChatCompletion.create(\n",
        "#         engine=\"gpt-35-turbo\",\n",
        "#         messages = [\n",
        "\n",
        "#                         {\"role\": \"system\", \"content\": \"You are a mathematics and linguistics professor setting a test.\"},\n",
        "\n",
        "#                         {\"role\": \"user\", \"content\": prompt_text}\n",
        "\n",
        "#                     ],\n",
        "#         temperature=0.7,\n",
        "#         max_tokens=800,\n",
        "#         top_p=0.95,\n",
        "#         frequency_penalty=0,\n",
        "#         presence_penalty=0,\n",
        "#         stop=None)\n",
        "\n",
        "#     ans = response[\"choices\"][0][\"message\"][\"content\"].split(\"\\n\")\n",
        "\n",
        "#     if(returnPrompt):\n",
        "#         return [prompt_text,ans]\n",
        "#     else:\n",
        "#         return [ans] \n",
        "\n",
        "\n",
        "\n",
        "def getInference(prompt_text, returnPrompt=False):\n",
        "\n",
        "    # print(prompt_text)\n",
        "    # print(type(prompt_text))\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "    # response = client.completions.create(\n",
        "        model=\"gpt-35-turbo\",\n",
        "        messages = [\n",
        "\n",
        "                        {\"role\": \"system\", \"content\": \"You are a mathematician.\"},\n",
        "\n",
        "                        {\"role\": \"user\", \"content\": prompt_text}\n",
        "\n",
        "                    ],\n",
        "        temperature=0.7,\n",
        "        max_tokens=800,\n",
        "        top_p=0.95,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0,\n",
        "        stop=None)\n",
        "\n",
        "    ans = response.choices[0].message.content\n",
        "\n",
        "    if(returnPrompt):\n",
        "        return [prompt_text,ans[0]]\n",
        "    else:\n",
        "        return [ans ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1698156952665
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "ipfile = 'stage4_train_processed_data.json'\n",
        "opfile = 'SIMPLE-stage_4_with_adversarial_TRAIN.csv'\n",
        "\n",
        "# ipfile = 'stage2_test_with_answer_processed_data.json'\n",
        "# opfile = 'stage_2_with_adversarial_TEST.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1698156952918
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 2 entries, passage to qa_pairs\n",
            "Columns: 472 entries, passage_0 to passage_471\n",
            "dtypes: object(472)\n",
            "memory usage: 7.4+ KB\n"
          ]
        }
      ],
      "source": [
        "file = pd.read_json(ipfile)\n",
        "file.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1687135209304
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1698156953094
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "passage_ids = file.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1687148358855
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1687281524415
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1698156953801
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "ip_list2 = passage_ids\n",
        "\n",
        "count = 0\n",
        "\n",
        "batch_size = 50  #Tunable parameter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1698156953986
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1698156954161
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "total_shards = len(ip_list2)/batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1698156954365
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9.44"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_shards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1698157755538
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "creating shard  0\n",
            "shard number: 1 Done\n",
            "creating shard  1\n",
            "shard number: 2 Done\n",
            "creating shard  2\n",
            "shard number: 3 Done\n",
            "creating shard  3\n",
            "shard number: 4 Done\n",
            "creating shard  4\n",
            "shard number: 5 Done\n",
            "creating shard  5\n",
            "shard number: 6 Done\n",
            "creating shard  6\n",
            "shard number: 7 Done\n",
            "creating shard  7\n",
            "shard number: 8 Done\n",
            "creating shard  8\n",
            "shard number: 9 Done\n",
            "creating shard  9\n",
            "shard number: 10 Done\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [01:22<00:00,  1.65s/it]\n",
            "100%|██████████| 50/50 [01:22<00:00,  1.65s/it]\n",
            "100%|██████████| 50/50 [01:29<00:00,  1.78s/it]\n",
            "100%|██████████| 50/50 [01:31<00:00,  1.83s/it]\n",
            "100%|██████████| 50/50 [01:26<00:00,  1.74s/it]\n",
            "100%|██████████| 50/50 [01:20<00:00,  1.61s/it]\n",
            "100%|██████████| 50/50 [01:26<00:00,  1.74s/it]\n",
            "100%|██████████| 50/50 [01:24<00:00,  1.69s/it]\n",
            "100%|██████████| 50/50 [01:15<00:00,  1.52s/it]\n",
            "100%|██████████| 22/22 [00:39<00:00,  1.82s/it]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "while len(ip_list2) > 0:\n",
        "    temp_list = ip_list2[:batch_size]\n",
        "\n",
        "    para=[]\n",
        "    question=[]\n",
        "    answer=[]\n",
        "    query_id=[]\n",
        "    is_adversarial=[]\n",
        "    passage_ids_L=[]\n",
        "\n",
        "    print('creating shard ',count)\n",
        " \n",
        "\n",
        "    for p in tqdm.tqdm(temp_list):\n",
        "        passage_ids_L.append(p)\n",
        "        passage_ids_L.append(p)\n",
        "\n",
        "        para.append(file[p]['passage'])\n",
        "        question.append(file[p]['qa_pairs'][0]['question'])\n",
        "        answer.append(file[p]['qa_pairs'][0]['answer'])\n",
        "        query_id.append(file[p]['qa_pairs'][0]['query_id'])\n",
        "        is_adversarial.append(False)\n",
        "\n",
        "        para.append(getInference(getPrompt(file[p]['passage'])))\n",
        "        question.append(file[p]['qa_pairs'][0]['question'])\n",
        "        answer.append(file[p]['qa_pairs'][0]['answer'])\n",
        "        query_id.append(file[p]['qa_pairs'][0]['query_id'])\n",
        "        is_adversarial.append(True)\n",
        "    \n",
        "    dff = pd.DataFrame(data={'passage_id':passage_ids_L,\n",
        "                        'passage':para,\n",
        "                        'question':question,\n",
        "                        'answer':answer,\n",
        "                        'query_id':query_id,\n",
        "                        'isAdversarial':is_adversarial})\n",
        "\n",
        "    dff.to_csv(opfile.replace('.csv','_SHARD_{}.csv'.format(count)),index=False)\n",
        "    \n",
        "    count+=1\n",
        "    print(\"shard number:\",count,\"Done\")\n",
        "    ip_list2 = ip_list2[batch_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1698157755725
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1698157755893
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# ip_list = list(df[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1698157756048
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "    # para.append(getInference(getPrompt(file[p]['passage'])))\n",
        "    # question.append(file[p]['qa_pairs'][0]['question'])\n",
        "    # answer.append(file[p]['qa_pairs'][0]['answer'])\n",
        "    # query_id.append(file[p]['qa_pairs'][0]['query_id'])\n",
        "    # is_adversarial.append(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1687233260385
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "gather": {
          "logged": 1698157756207
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# dff[dff.isAdversarial==True]['passage'].iloc[5]#[0][1].split(':')[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1698157756368
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# dff.loc[dff['isAdversarial']==True\n",
        "#                 , 'para'] = dff.loc[dff['isAdversarial']==True,'para'].str.split('Augmented:').str[-1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1687139053740
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1698157756689
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# dff.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "gather": {
          "logged": 1698157756886
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# file['passage_37']['qa_pairs'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
